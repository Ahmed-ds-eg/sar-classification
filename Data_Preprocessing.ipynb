{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code is importing the necessary libraries for the program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Hyperparameters best practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c 4 -p 21 --dataset sfbay_l -W 1024 -H 900 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c 4 -p 21 --dataset sfbay_c -W 1426 -H 1876 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c 6 -p 7 --dataset flevo_l -W 1024 -H 750"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c 6 -p 21 --dataset flevo_c -W 1639 -H 2393"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enter input <br>\n",
    "* **dataset choose from [sfbay_l, sfbay_c, flevo_l, or flevo_c]**<br>\n",
    "* **channels number of channels choose form 3 or 4 or 6**<br>\n",
    "* **patch sliding window patch size**<br>\n",
    "* **W  width size of the scene**<br>\n",
    "* **H  height of the scene**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Data_entry ():\n",
    "    \"\"\"\n",
    "    This function takes the name of the dataset, the number of channels, the window size, the width and\n",
    "    the height of the image as input and returns the name of the dataset, the number of channels, the\n",
    "    window size, the width and the height of the image and the file size\n",
    "    \"\"\"\n",
    "    args={} \n",
    "    args[\"data\"]=input(\"please enter dataset name \\n\")\n",
    "    args[\"channels\"]=int(input(\"Please enter number of channels \\n\"))\n",
    "    \n",
    "    args[\"patch\"]=int(input(\"please enter window size \\n\" ))\n",
    "    args[\"W\"]=int(input(\"please enter width of the image \\n\"))\n",
    "    args[\"H\"]=int(input(\"please enter hight of the image \\n\"))\n",
    "    filesize = args[\"W\"] * args[\"H\"]\n",
    "    return args[\"data\"],args[\"channels\"],args[\"patch\"],args[\"W\"],args[\"H\"],filesize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining Dataset with it's Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset,channels,patch_size,m_W,m_H,filesize=Data_entry ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_row(filename):\n",
    "    \"\"\"\n",
    "    It reads a binary file, and returns a numpy array of the data\n",
    "    \n",
    "    :param filename: the name of the file to be read\n",
    "    :return: the data from the file in the form of an array.\n",
    "    \"\"\"\n",
    "    rdata = np.zeros(filesize, dtype = 'float32')\n",
    "    f = open(filename, 'rb')\n",
    "    for l in range(0, +filesize):\n",
    "        (num,) = struct.unpack('f', f.read(4))\n",
    "        rdata[l] = num\n",
    "    return rdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the data from the binary files and saving it in a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_data = np.zeros((filesize, channels), dtype = 'float32')\n",
    "if channels == 3:\n",
    "    filenames = ['C11dbs.bin', 'C22dbs.bin', 'C33dbs.bin']#['T11dbs.bin', 'T22dbs.bin', 'T33dbs.bin']\n",
    "elif channels == 4:\n",
    "    filenames = ['T11dbs.bin', 'T22dbs.bin', 'T33dbs.bin', 'span_dbs.bin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elif channels == 5:\n",
    "    filenames = ['T11dbs.bin', 'T22dbs.bin', 'T33dbs.bin', 'C11dbs.bin', 'C22dbs.bin']\n",
    "    \n",
    "elif channels == 6:\n",
    "    filenames = ['T11dbs.bin', 'C11dbs.bin' ,'T22dbs.bin','C22dbs.bin', 'T33dbs.bin',  'C33dbs.bin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, channels):\n",
    "    row_data[:, i] = read_row(dataset+ '/' + filenames[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dataset + '/' + dataset + '_' + str(channels) + '_rowdata.pkl', 'wb') as f:\n",
    "    pickle.dump([row_data], f, protocol = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the size of the training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == 'sfbay_l':\n",
    "    train_size = 1462 # SFBay_L\n",
    "    test_size = 121997 # SFBay_L\n",
    "elif dataset == 'sfbay_c':\n",
    "    train_size = 2500 # SFBay_C\n",
    "    test_size = 250000 # SFBay_C\n",
    "elif dataset == 'flevo_l':\n",
    "    train_size = 4211 # Flevo_L\n",
    "    test_size = 204023 # Flevo_L\n",
    "elif dataset == 'flevo_c':\n",
    "    train_size = 2000 # Flevo_C\n",
    "    test_size = 200000 # Flevo_C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the data from the two files, and returns the data as two numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_gtd(filename, size):\n",
    "    \"\"\"\n",
    "    It reads in the data from the two files, and returns the data as two numpy arrays\n",
    "    \n",
    "    :param filename: the name of the file you want to read\n",
    "    :param size: the number of data points in the file\n",
    "    :return: the positions and labels of the data.\n",
    "    \"\"\"\n",
    "    positions = np.zeros((size,), dtype = 'float32')\n",
    "    labels = np.zeros((size,), dtype = 'float32')\n",
    "    f1 = open(filename + '_positions.gtd', 'rb')\n",
    "    f2 = open(filename + '_labels.gtd', 'rb')\n",
    "    for l in range(0, size):\n",
    "        (num1,) = struct.unpack('f', f1.read(4))\n",
    "        (num2,) = struct.unpack('f', f2.read(4))\n",
    "        positions[l] = num1\n",
    "        labels[l] = num2\n",
    "    return positions, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_positions, train_labels = read_gtd(dataset + '/' + dataset + '_train', train_size)\n",
    "test_positions, test_labels = read_gtd(dataset+ '/' + dataset + '_test', test_size)\n",
    "#Converting from float to int\n",
    "train_positions = np.array(train_positions, dtype = 'int')\n",
    "test_positions = np.array(test_positions, dtype = 'int')\n",
    "train_labels = np.array(train_labels, dtype = 'int')\n",
    "test_labels = np.array(test_labels, dtype = 'int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the data from the pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dataset + '/' + dataset + '_' + str(channels) + '_rowdata.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshaping the data to the size of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data[0])\n",
    "data = np.reshape(data, [m_H, m_W, channels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_padded = np.zeros([m_H + patch_size - 1, m_W + patch_size - 1, channels], dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Padding the data with zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startid = (patch_size - 1) // 2\n",
    "data_padded[startid:startid + m_H, startid:startid + m_W, :] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_padded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a patch of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_data = np.zeros([filesize, patch_size, patch_size, channels], dtype = 'float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "for i in range(startid, startid + m_H):\n",
    "    for j in range(startid, startid + m_W):\n",
    "        for c in range(0, channels):\n",
    "            patch_data[index, :, :, c] = data_padded[i - startid : i + startid + 1, j - startid : j + startid + 1, c]\n",
    "        index = index + 1\n",
    "print('Processed: ', (index/filesize)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking  patch data shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( patch_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(patch_data[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the patch data in a pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dataset + '/' + dataset + '_' + str(channels) + '_' + str(patch_size) + '_' + 'patchdata' + '.pkl', 'wb') as f:\n",
    "    pickle.dump(patch_data, f, protocol = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a matrix of zeros with the size of the training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.zeros([train_size, patch_size, patch_size, channels], dtype = 'float32')\n",
    "test_data = np.zeros([test_size, patch_size, patch_size, channels], dtype = 'float32')\n",
    "train_data = patch_data[train_positions]\n",
    "test_data = patch_data[test_positions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the data in a pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dataset + '/' + dataset + '_' + str(channels) + '_' + str(patch_size) +'.pkl', 'wb') as f:\n",
    "    pickle.dump([train_data, train_labels, test_data, test_labels], f, protocol = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change  labels of flevo_l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the data from the pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset,channels,patch_size,m_W,m_H,filesize=Data_entry ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dataset  + '/' + dataset + '_' + str(channels) + '_' + str(patch_size) +'.pkl', 'rb') as f:\n",
    "       x_train, y_train,  x_test, y_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for the number of classes in trainning dataset\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "print(np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing the labels of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropland = [2,4,5,6,7,8,10,11,12,13]\n",
    "label_new_train = [] \n",
    "for i in y_train:\n",
    "    if i == 3:\n",
    "        i = 1\n",
    "    elif i in cropland:\n",
    "        i = 3\n",
    "    elif i == 14 or i == 9:\n",
    "        i = 2\n",
    "    label_new_train.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for the number of classes after converting classes\n",
    "unique, counts = np.unique(label_new_train, return_counts=True)\n",
    "print(np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_new_train = np.array(label_new_train)\n",
    "label_new_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for the number of classes in testing Dataset\n",
    "unique, counts = np.unique(y_test, return_counts=True)\n",
    "print(np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing the labels of the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropland = [2,4,5,6,7,8,10,11,12,13]\n",
    "label_new_test = [] \n",
    "for i in y_test:\n",
    "    if i == 3:\n",
    "        i = 1\n",
    "    elif i in cropland:\n",
    "        i = 3\n",
    "    elif i == 14 or i == 9:\n",
    "        i = 2\n",
    "    label_new_test.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for the number of classes after converting classes\n",
    "unique, counts = np.unique(label_new_test, return_counts=True)\n",
    "print(np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_new_test = np.array(label_new_test)\n",
    "label_new_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the data in a pickle file.\n",
    "with open(dataset + '/' + dataset + '_' + str(channels) + '_' + str(patch_size) + '_' + '4-classes' + '.pkl', 'wb') as f:\n",
    "    pickle.dump([train_data, label_new_train, test_data, label_new_test], f, protocol = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the necessary libraries for the program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Showing the image of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_pickle(f\"{dataset}/{dataset}_{str(channels)}_rowdata.pkl\")\n",
    "df2 = df2[0]\n",
    "df2 = np.reshape(df2, [m_H, m_W, channels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.namedWindow(\"image\", cv2.WINDOW_NORMAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('image', df2[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.waitKey(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
