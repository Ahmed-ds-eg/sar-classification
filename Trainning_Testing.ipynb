{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Needed Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense , GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import Callback, LearningRateScheduler, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_CNN_Mod(input_shape, N):\n",
    "    \"\"\"\n",
    "    We take an input image, pass it through a convolutional layer with 20 filters, then a max pooling\n",
    "    layer, then another convolutional layer with 15 filters, then another max pooling layer, then a\n",
    "    flatten layer, then a dense layer with 10 neurons, then a final dense layer with N neurons, where N\n",
    "    is the number of classes\n",
    "    \n",
    "    :param input_shape: the shape of the input image\n",
    "    :return: The model is being returned.\n",
    "    \"\"\"\n",
    "    \n",
    "    input = Input(shape = input_shape, name='input1')\n",
    "\n",
    "    # First branch\n",
    "    x_1 = Conv2D(20, 3, strides=1, activation='relu', padding = 'valid')(input)\n",
    "    x_1=MaxPooling2D(pool_size=2)(x_1)\n",
    "    x_1=Conv2D(15, 3, strides=1, activation='tanh', padding = 'valid')(x_1)\n",
    "    x_1 = MaxPooling2D(pool_size=x_1.shape[1])(x_1)\n",
    "    x_1 = Flatten()(x_1)\n",
    "    x_1 = Dense(10, activation=\"tanh\")(x_1)\n",
    "    y = Dense(N, activation=\"softmax\")(x_1)\n",
    "    \n",
    "    CNNmodel = Model(inputs = input, outputs = y)\n",
    "    return CNNmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_CNN(input_shape, N):\n",
    "    \"\"\"\n",
    "    We take an input of shape (28,28,1) and pass it through a convolutional layer with 20 filters of\n",
    "    size 3x3, followed by a global average pooling layer, a dense layer with 10 neurons, and a final\n",
    "    dense layer with 10 neurons (one for each class)\n",
    "    \n",
    "    :param input_shape: the shape of the input image\n",
    "    :return: The model is being returned.\n",
    "    \"\"\"\n",
    "    \n",
    "    input = Input(shape = input_shape, name='input1')\n",
    "\n",
    "    # First branch\n",
    "    x_1 = Conv2D(20, 3, strides=1, activation='tanh', padding = 'valid')(input)\n",
    "#     x_1 = MaxPooling2D(pool_size=x_1.shape[1])(x_1)\n",
    "#     x_1 = Flatten()(x_1)\n",
    "    x_1 = GlobalAveragePooling2D()(x_1)\n",
    "    x_1 = Dense(10, activation=\"relu\")(x_1)\n",
    "    y = Dense(N, activation=\"softmax\")(x_1)\n",
    "    \n",
    "    CNNmodel = Model(inputs = input, outputs = y)\n",
    "    return CNNmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Data_entry ():\n",
    "    \"\"\"\n",
    "    It takes the dataset name, number of channels, patch size, width and height of the image as input\n",
    "    and returns the dataset name, number of channels, patch size, width and height of the image and the\n",
    "    file size\n",
    "    \"\"\"\n",
    "    args={} \n",
    "    args[\"data\"]=input(\"please enter dataset name \\n\")\n",
    "    args[\"channels\"]=int(input(\"Please enter number of channels \\n\"))\n",
    "    \n",
    "    args[\"patch\"]=int(input(\"please enter window size \\n\" ))\n",
    "    args[\"W\"]=int(input(\"please enter width of the image \\n\"))\n",
    "    args[\"H\"]=int(input(\"please enter hight of the image \\n\"))\n",
    "    filesize = args[\"W\"] * args[\"H\"]\n",
    "    return args[\"data\"],args[\"channels\"],args[\"patch\"],args[\"W\"],args[\"H\"],filesize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the dataset input parameters\n",
    "dataset,channels,patch_size,m_W,m_H,filesize=Data_entry ()\n",
    "weights = False\n",
    "modelName = dataset+ '_patch_' + str(patch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the data from the pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dataset + '/' + dataset + '_' + str(channels) + '_' + str(patch_size) + '.pkl', 'rb') as f:############\n",
    "       x_train, y_train,  x_test, y_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the Data Limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Max and min values of data:\")\n",
    "print(x_test.max())\n",
    "print(x_test.min())\n",
    "print(x_train.max())\n",
    "print(x_train.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(np.unique(y_train))\n",
    "print('Number of classes: ', N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code is converting the y_train data into a categorical array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_temp_train = np.array(y_train)\n",
    "y_train = to_categorical(y_temp_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (x_train.shape[-3], x_train.shape[-2], x_train.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_CNN(input_shape, N)\n",
    "model.summary()\n",
    "model.compile(loss='mse', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_decay(epoch):\n",
    "    \"\"\"\n",
    "    The learning rate is dropped by a factor of 0.94 every 2 epochs\n",
    "    \n",
    "    :param epoch: The current epoch number\n",
    "    :return: The learning rate is being returned.\n",
    "    \"\"\"\n",
    "    initial_lrate = 0.1\n",
    "    drop = 0.94\n",
    "    epochs_drop = 2.0\n",
    "    lrate = initial_lrate * math.pow(drop,  math.floor((1+epoch)/epochs_drop))\n",
    "    return lrate\n",
    "lrate = LearningRateScheduler(step_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It stops training when the loss value is less than 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStoppingByLossVal(Callback):\n",
    "    def __init__(self, monitor='loss', value=0.01, verbose=0):\n",
    "        \"\"\"\n",
    "        This function is used to stop the training process when the monitored quantity has stopped\n",
    "        improving\n",
    "        \n",
    "        :param monitor: quantity to be monitored, defaults to loss (optional)\n",
    "        :param value: The threshold for measuring the new optimum, to only focus on significant changes\n",
    "        :param verbose: 0, 1, or 2. Verbosity mode. 0 = silent, 1 = progress bar, 2 = one line per\n",
    "        epoch, defaults to 0 (optional)\n",
    "        \"\"\"\n",
    "        super(Callback, self).__init__()\n",
    "        self.monitor = monitor\n",
    "        self.value = value\n",
    "        self.verbose = verbose\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \"\"\"\n",
    "        If the monitored quantity has stopped improving, then stop training\n",
    "        \n",
    "        :param epoch: the current epoch number\n",
    "        :param logs: the same dictionary that is passed to the on_epoch_end callback\n",
    "        \"\"\"\n",
    "        current = logs.get(self.monitor)\n",
    "        if current is None:\n",
    "            warnings.warn(\"Early stopping requires %s available!\" % self.monitor, RuntimeWarning)\n",
    "        if current < self.value:\n",
    "            if self.verbose > 0:\n",
    "                print(\"Epoch %05d: early stopping THR\" % epoch)\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = ModelCheckpoint(modelName + '.h5', monitor='accuracy', mode='max', save_best_only=True, verbose=1)\n",
    "callbacks_list = [lrate, mc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if weights:\n",
    "    model.load_weights(modelName + '.h5')\n",
    "else:\n",
    "    history = model.fit(x_train, y_train, epochs = 150, batch_size = 1, shuffle = True, callbacks = callbacks_list)\n",
    "    # The below code is saving the loss history of the model.\n",
    "    model.load_weights(modelName + '.h5')\n",
    "    loss_history = history.history[\"loss\"]\n",
    "    numpy_loss_history = np.array(loss_history)\n",
    "    np.savetxt(modelName + \"_loss_history.txt\", numpy_loss_history, delimiter=\",\")\n",
    "    with open(modelName + '_loss.pkl', 'wb') as f:\n",
    "        pickle.dump([numpy_loss_history], f, protocol = 4)\n",
    "    #plotting the graph of the model and the loss curve\n",
    "    plt.figure(0)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.savefig(modelName + \"_loss.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting the testing dataset and checking the score\n",
    "y_pred = model.predict(x_test)\n",
    "#y_pred = model.predict([x_test])\n",
    "y_pred = np.argmax(y_pred, axis = 1)\n",
    "print(\"Test accuracy is: \", accuracy_score(y_pred, y_test))\n",
    "C = confusion_matrix(y_test, y_pred)\n",
    "print(\"Class Accuracies: \")\n",
    "s = 0\n",
    "for i in range(0, C.shape[0]):\n",
    "    s = s + C[i,i]\n",
    "    print(C[i,i]/np.sum(C[i, :]))\n",
    "print(\"Accuracy: \", s / len(y_pred))\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the Model with best weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(r'Models/'+ dataset + '_' + 'model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code is loading the data from the pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset,channels,patch_size,m_W,m_H,filesize=Data_entry ()\n",
    "with open(dataset + '/' + dataset + '_' + str(channels) + '_' + str(patch_size) + '_' + 'patchdata' + '.pkl', 'rb') as f:\n",
    "    Patch_Data_c = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sfbay_c<br>\n",
    "colors_c = np.zeros([5, 3])<br>\n",
    "colors_c[0, :] = [57, 83, 160]<br>\n",
    "colors_c[1, :] = [232, 33, 38]<br>\n",
    "colors_c[2, :] = [185, 79, 151]<br>\n",
    "colors_c[3, :] = [283, 97, 105]<br>\n",
    "colors_c[4, :] = [104, 192, 70]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code is creating a 15x3 matrix of zeros. Then, it is assigning the RGB values to each row<br>\n",
    "of the matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flevo_l\n",
    "colors_c = np.zeros([15, 3])\n",
    "colors_c[0, :] = [0, 1, 254]\n",
    "colors_c[1, :] = [0, 131, 71]\n",
    "colors_c[2, :] = [0, 253, 255]\n",
    "colors_c[3, :] = [0, 255, 0]\n",
    "colors_c[4, :] = [255, 126, 0]\n",
    "colors_c[5, :] = [180, 0, 255]\n",
    "colors_c[6, :] = [251, 255, 7]\n",
    "colors_c[7, :] = [91, 8, 227]\n",
    "colors_c[8, :] = [253, 0, 0]\n",
    "colors_c[9, :] = [172, 138, 78]\n",
    "colors_c[10, :] = [255, 181, 230]\n",
    "colors_c[11, :] = [191, 191, 255]\n",
    "colors_c[12, :] = [201, 222, 188]\n",
    "colors_c[13, :] = [127, 21, 25]\n",
    "colors_c[14, :] = [249, 226, 150]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "flevo_c<br>\n",
    "colors_c = np.zeros([4, 3])<br>\n",
    "colors_c[0, :] = [0, 1, 254]<br>\n",
    "colors_c[1, :] = [0, 131, 71]<br>\n",
    "colors_c[2, :] = [253, 0, 0]<br>\n",
    "colors_c[3, :] = [0, 253, 255]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting labels for the whole image\n",
    "y_all_c = model.predict(Patch_Data_c)\n",
    "y_all_c = np.argmax(y_all_c, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code is creating a color mask for the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_mask_c = np.zeros([m_H, m_W, 3])\n",
    "counter = 0\n",
    "for i in range(0, m_H):\n",
    "    for j in range(0, m_W):\n",
    "        color_mask_c[i, j, :] = colors_c[y_all_c[counter], :]\n",
    "        counter = counter + 1\n",
    "import cv2\n",
    "color_mask = color_mask_c.astype(np.uint8)\n",
    "color_mask = cv2.cvtColor(color_mask, cv2.COLOR_BGR2RGB)\n",
    "cv2.imwrite(\"file_dataset.jpg\", color_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the label positions of the testing data only and mask it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_gtd(filename, size):\n",
    "    \"\"\"\n",
    "    It reads the gtd files and converts them to numpy arrays\n",
    "    \n",
    "    :param filename: the name of the file to be read\n",
    "    :param size: The number of samples in the dataset\n",
    "    :return: The positions and labels of the test set.\n",
    "    \"\"\"\n",
    "    positions = np.zeros((size,), dtype = 'float32')\n",
    "    labels = np.zeros((size,), dtype = 'float32')\n",
    "    f1 = open(filename + '_positions.gtd', 'rb')\n",
    "    f2 = open(filename + '_labels.gtd', 'rb')\n",
    "    for l in range(0, size):\n",
    "        (num1,) = struct.unpack('f', f1.read(4))\n",
    "        (num2,) = struct.unpack('f', f2.read(4))\n",
    "        positions[l] = num1\n",
    "        labels[l] = num2\n",
    "    return positions, labels\n",
    "### Read gtd\n",
    "test_positions, test_labels = read_gtd(dataset+ '/' + dataset + '_test', test_size)\n",
    "#Converting from float to int\n",
    "test_positions = np.array(test_positions, dtype = 'int')\n",
    "test_labels = np.array(test_labels, dtype = 'int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a mask of the image with the colors of the predicted classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_mask_layout_c = np.zeros([m_H, m_W, 3])\n",
    "counter = 0\n",
    "for i in range(0, m_H):\n",
    "    for j in range(0, m_W):\n",
    "        if counter in test_positions: color_mask_layout_c[i, j, :] = colors_c[y_all_c[counter], :]\n",
    "        counter = counter + 1\n",
    "import cv2\n",
    "color_mask_layout = color_mask_layout_c.astype(np.uint8)\n",
    "color_mask_layout = cv2.cvtColor(color_mask_layout, cv2.COLOR_BGR2RGB)\n",
    "cv2.imwrite(\"file22_c.jpg\", color_mask_layout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction and Masking for the sfbay_l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "our nobel approach of trainning the model on c-band and predict the l-band labels<br>\n",
    "Loading the data from the pickle file. (General Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset,channels,patch_size,m_W,m_H,filesize=Data_entry ()\n",
    "with open(dataset + '/' + dataset + '_' + str(channels) + '_' + str(patch_size) + '_' + 'patchdata' + '.pkl', 'rb') as f:############\n",
    "    Patch_Data_l = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code is creating a 4x3 matrix of zeros. Then, it is assigning the first row of the matrix<br>\n",
    "to the RGB values of the first color. It is doing the same for the other three colors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sfbay_l\n",
    "colors_l = np.zeros([4, 3])\n",
    "colors_l[0, :] = [0, 1, 254]\n",
    "colors_l[1, :] = [0, 131, 71]\n",
    "colors_l[2, :] = [253, 0, 0]\n",
    "colors_l[3, :] = [0, 253, 255]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all_l = model.predict(Patch_Data_l)\n",
    "y_all_l = np.argmax(y_all_l, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset,channels,patch_size,m_W,m_H,filesize=Data_entry ()\n",
    "with open(dataset  + '/' + dataset + '_' + str(channels) + '_' + str(patch_size) + '.pkl', 'rb') as f:\n",
    "       x_ltrain, y_ltrain,  x_ltest, y_ltest = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x_ltest)\n",
    "#y_pred = model.predict([x_test])\n",
    "pred = np.argmax(pred, axis = 1)\n",
    "print(\"Test accuracy is: \", accuracy_score(pred, y_ltest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = confusion_matrix(y_ltest, pred)\n",
    "print(\"Class Accuracies: \")\n",
    "s = 0\n",
    "for i in range(0, C.shape[0]):\n",
    "    s = s + C[i,i]\n",
    "    print(C[i,i]/np.sum(C[i, :]))\n",
    "print(\"Accuracy: \", s / len(pred))\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code is creating a color mask for the left image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_mask_l = np.zeros([m_H, m_W, 3])\n",
    "counter = 0\n",
    "for i in range(0, m_H):\n",
    "    for j in range(0, m_W):\n",
    "        color_mask_l[i, j, :] = colors_l[y_all_l[counter], :]\n",
    "        counter = counter + 1\n",
    "import cv2\n",
    "color_mask = color_mask_l.astype(np.uint8)\n",
    "color_mask = cv2.cvtColor(color_mask, cv2.COLOR_BGR2RGB)\n",
    "cv2.imwrite(\"file12_l.jpg\", color_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "def read_gtd(filename, size):\n",
    "    positions = np.zeros((size,), dtype = 'float32')\n",
    "    labels = np.zeros((size,), dtype = 'float32')\n",
    "    f1 = open(filename + '_positions.gtd', 'rb')\n",
    "    f2 = open(filename + '_labels.gtd', 'rb')\n",
    "    for l in range(0, size):\n",
    "        (num1,) = struct.unpack('f', f1.read(4))\n",
    "        (num2,) = struct.unpack('f', f2.read(4))\n",
    "        positions[l] = num1\n",
    "        labels[l] = num2\n",
    "    return positions, labels\n",
    "### Read gtd\n",
    "test_positions, test_labels = read_gtd(dataset+ '/' + dataset + '_test', test size)\n",
    "#Converting from float to int\n",
    "test_positions = np.array(test_positions, dtype = 'int')\n",
    "test_labels = np.array(test_labels, dtype = 'int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a mask of the layout of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_mask_layout_l = np.zeros([m_H, m_W, 3])\n",
    "counter = 0\n",
    "for i in range(0, m_H):\n",
    "    for j in range(0, m_W):\n",
    "        if counter in test_positions: color_mask_layout_l[i, j, :] = colors_l[y_all_l[counter], :]\n",
    "        counter = counter + 1\n",
    "import cv2\n",
    "color_mask_layout = color_mask_layout_l.astype(np.uint8)\n",
    "color_mask_layout = cv2.cvtColor(color_mask_layout, cv2.COLOR_BGR2RGB)\n",
    "cv2.imwrite(\"file2_l.jpg\", color_mask_layout)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "3911db4bc27f2948b8a5852955d3784b9dffaf470d3ac4bd2f2de7cd8c998848"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
